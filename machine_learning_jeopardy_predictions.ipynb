{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "jeopardy = pd.read_csv(\"jeopardy.csv\")\n",
    "\n",
    "#print(jeopardy[:5])\n",
    "#print(jeopardy.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy.columns = [c[1:] if c[0]==\" \" else c for c in jeopardy.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Show Number     int64\n",
       "Air Date       object\n",
       "Round          object\n",
       "Category       object\n",
       "Value          object\n",
       "Question       object\n",
       "Answer         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(\"[^A-Za-z0-9\\s]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def normalize_dollar_vals(col):\n",
    "    val = re.sub(\"[^A-Za-z0-9\\s]\", \"\", col)\n",
    "    try:\n",
    "        val = int(val)\n",
    "    except Exception:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy['clean_question'] = jeopardy['Question'].apply(normalize_text)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normalize_text)\n",
    "jeopardy['clean_value'] = jeopardy['Value'].apply(normalize_dollar_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_cols(row):\n",
    "    split_question = row['clean_question'].split(\" \")\n",
    "    split_answer = row['clean_answer'].split(\" \")\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    match_count = 0\n",
    "    for a in split_answer:\n",
    "        if a in split_question:\n",
    "            match_count += 1\n",
    "    return match_count / len(split_answer)\n",
    "\n",
    "jeopardy['answer_in_question'] = jeopardy.apply(split_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.060493257069335872"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['answer_in_question'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean of Answers in Questions\n",
    "I wouldn't spend my time studying answers in questions, as this occurs only 6% of the time based on the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy.sort_values('Air Date', inplace=True)\n",
    "terms_used = set()\n",
    "question_overlap = []\n",
    "for i, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split(\" \")\n",
    "    split_question = [s for s in split_question if len(s) > 5]\n",
    "    match_count=0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "\n",
    "jeopardy['question_overlap'] = question_overlap        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68762605921698017"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['question_overlap'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Overlap\n",
    "Interestingly, there's close to 70% of overlap in words between questions, though this is not a complete data set. Also, only looking at words themselves have no meaning without context in sentences/phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hi_lo_val(row):\n",
    "    value = 0\n",
    "    if row['clean_value'] > 800:\n",
    "        value=1\n",
    "    return value\n",
    "\n",
    "jeopardy['high_value'] = jeopardy.apply(hi_lo_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hi_lo_count(word):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        if word in row['clean_question'].split(\" \"):\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count\n",
    "\n",
    "observed_expected = []\n",
    "comparison_terms = list(terms_used)[:5]\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(hi_lo_count(term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (6, 11), (1, 1), (1, 0), (0, 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_value_count = len([v for v in jeopardy['high_value'] if v == 1])\n",
    "low_value_count = len([v for v in jeopardy['high_value'] if v == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.40196284612688399, pvalue=0.52607729857054686),\n",
       " Power_divergenceResult(statistic=0.36458944708219171, pvalue=0.54596835640997887),\n",
       " Power_divergenceResult(statistic=0.44487748166127949, pvalue=0.50477764875459963),\n",
       " Power_divergenceResult(statistic=2.4877921171956752, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.40196284612688399, pvalue=0.52607729857054686)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "chi_squared = []\n",
    "for obs in observed_expected:\n",
    "    total = sum(obs)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    exp_term_count_high = total_prop * high_value_count\n",
    "    exp_term_count_low = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([obs[0], obs[1]])\n",
    "    expected = np.array([exp_term_count_high, exp_term_count_low])\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "    \n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
